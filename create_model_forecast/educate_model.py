import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from catboost import CatBoostRegressor, Pool
import joblib
import optuna


def prepare_data(csv_path: str):
    df = pd.read_csv(csv_path)

    df['–ò–∑–º–µ–Ω–µ–Ω–∏–µ –±–∞–ª–∞–Ω—Å–∞'] = pd.to_numeric(df['–ò–∑–º–µ–Ω–µ–Ω–∏–µ –±–∞–ª–∞–Ω—Å–∞'], errors='coerce')
    df['–ë–∞–ª–∞–Ω—Å'] = pd.to_numeric(df['–ë–∞–ª–∞–Ω—Å'], errors='coerce')
    df['–î–µ–Ω—å –ø–æ–∫—É–ø–∫–∏'] = pd.to_numeric(df['–î–µ–Ω—å –ø–æ–∫—É–ø–∫–∏'], errors='coerce')
    df['–ú–µ—Å—è—Ü –ø–æ–∫—É–ø–∫–∏'] = pd.to_numeric(df['–ú–µ—Å—è—Ü –ø–æ–∫—É–ø–∫–∏'], errors='coerce')
    df = df.dropna()

    # –¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è ‚Äî –±–∞–ª–∞–Ω—Å —Å–ª–µ–¥—É—é—â–µ–π —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏
    df['target'] = df['–ë–∞–ª–∞–Ω—Å'].shift(-1)
    df = df.dropna()

    X = df[['–ò–∑–º–µ–Ω–µ–Ω–∏–µ –±–∞–ª–∞–Ω—Å–∞', '–ë–∞–ª–∞–Ω—Å', '–î–µ–Ω—å –ø–æ–∫—É–ø–∫–∏', '–ú–µ—Å—è—Ü –ø–æ–∫—É–ø–∫–∏', '–ö–∞—Ç–µ–≥–æ—Ä–∏—è']]
    y = df['target']

    cat_features = ['–ö–∞—Ç–µ–≥–æ—Ä–∏—è']
    return X, y, cat_features


def objective(trial, X_train, y_train, X_val, y_val, cat_features):
    params = {
        "iterations": trial.suggest_int("iterations", 100, 1000),
        "depth": trial.suggest_int("depth", 4, 10),
        "learning_rate": trial.suggest_float("learning_rate", 0.01, 0.3),
        "l2_leaf_reg": trial.suggest_float("l2_leaf_reg", 1e-3, 10.0, log=True),
        "random_strength": trial.suggest_float("random_strength", 1e-3, 10.0, log=True),
        "loss_function": "MAE",
        "verbose": 0,
        "random_seed": 42
    }

    model = CatBoostRegressor(**params)
    model.fit(X_train, y_train, cat_features=cat_features)

    preds = model.predict(X_val)
    mae = mean_absolute_error(y_val, preds)
    return mae


def train_model(csv_path: str, model_path="catboost_model.pkl"):
    X, y, cat_features = prepare_data(csv_path)

    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

    print("üîç –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —Å –ø–æ–º–æ—â—å—é Optuna...")
    study = optuna.create_study(direction="minimize")
    study.optimize(lambda trial: objective(trial, X_train, y_train, X_val, y_val, cat_features), n_trials=30)

    print(f"‚úÖ –õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã: {study.best_params}")

    best_model = CatBoostRegressor(**study.best_params, loss_function="MAE", verbose=0)
    best_model.fit(X_train, y_train, cat_features=cat_features)

    # –ú–µ—Ç—Ä–∏–∫–∏
    def evaluate(model, X, y, dataset_name=""):
        preds = model.predict(X)
        mae = mean_absolute_error(y, preds)
        rmse = np.sqrt(mean_squared_error(y, preds))
        r2 = r2_score(y, preds)
        print(f"üìä –ú–µ—Ç—Ä–∏–∫–∏ –¥–ª—è {dataset_name}:")
        print(f"  MAE:  {mae:.2f}")
        print(f"  RMSE: {rmse:.2f}")
        print(f"  R¬≤:   {r2:.4f}\n")

    evaluate(best_model, X_train, y_train, "Train")
    evaluate(best_model, X_val, y_val, "Test")

    joblib.dump((best_model, cat_features), model_path)
    print(f"üíæ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤: {model_path}")


# –ó–∞–ø—É—Å–∫
train_model("/home/fotuneb/ML/dataset.csv")  # –£–∫–∞–∂–∏ –ø—É—Ç—å –∫ —Å–≤–æ–µ–º—É CSV
